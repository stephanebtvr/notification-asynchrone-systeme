package com.kafka.notification_service.service;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.messaging.simp.SimpMessagingTemplate;
import org.springframework.stereotype.Component;

import com.kafka.notification_service.dto.NotificationDto;

/**
 * Consumer Kafka pour √©couter et traiter les notifications.
 * 
 * Responsabilit√©s :
 * 1. √âcouter le topic Kafka "notifications-topic"
 * 2. D√©s√©rialiser automatiquement les messages JSON en NotificationDTO
 * 3. Broadcaster les notifications via WebSocket √† tous les clients connect√©s
 * 4. Logger les op√©rations pour monitoring et debugging
 * 
 * @Component : Marque cette classe comme un composant Spring g√©r√© automatiquement.
 *              Spring la d√©tecte via component scan et l'instancie au d√©marrage.
 * 
 * Pourquoi un Component et pas un Service ?
 * - @Component est g√©n√©rique pour tous les composants Spring
 * - @Service est une sp√©cialisation pour la logique m√©tier
 * - Ici, c'est un listener (infrastructure), donc @Component est plus appropri√©
 * - Alternativement, on pourrait utiliser @Service (√ßa marche aussi)
 */
@Component
public class NotificationConsumer {
    
    /**
     * Logger SLF4J pour tracer les op√©rations du consumer.
     * 
     * Importance du logging c√¥t√© consumer :
     * - V√©rifier que les messages sont bien re√ßus
     * - Mesurer le d√©bit (nombre de messages/seconde)
     * - D√©tecter les erreurs de traitement
     * - Audit : tracer qui a re√ßu quoi et quand
     */
    private static final Logger logger = LoggerFactory.getLogger(NotificationConsumer.class);
    
    /**
     * SimpMessagingTemplate : Composant Spring WebSocket pour envoyer des messages.
     * 
     * "Simp" = Simple Messaging Protocol (sous-ensemble de STOMP)
     * STOMP = Simple Text Oriented Messaging Protocol
     * 
     * Fonctionnalit√©s principales :
     * - convertAndSend(destination, payload) : Envoie un message √† une destination
     * - Conversion automatique Java ‚Üí JSON
     * - Broadcast √† tous les clients abonn√©s √† la destination
     * - Thread-safe (peut √™tre utilis√© en parall√®le)
     * 
     * @Autowired : Injection de d√©pendances par Spring.
     *              Spring injecte automatiquement le bean SimpMessagingTemplate
     *              configur√© dans WebSocketConfig.
     */
    @Autowired
    private SimpMessagingTemplate messagingTemplate;
    
    /**
     * Destination WebSocket o√π broadcaster les notifications.
     * 
     * @Value : Lit la propri√©t√© depuis application.properties.
     * "/topic/notifications" : Convention STOMP pour les destinations broadcast.
     * 
     * Distinction /topic vs /queue :
     * - /topic/* : Publish-Subscribe (broadcast √† TOUS les abonn√©s)
     * - /queue/* : Point-to-Point (message √† UN SEUL client)
     * 
     * Pour nos notifications : /topic car on veut que TOUS les utilisateurs
     * connect√©s re√ßoivent la notification (comme un chat public).
     */
    @Value("${websocket.notification-destination}")
    private String notificationDestination;
    
    /**
     * M√©thode listener Kafka - Point d'entr√©e pour les messages du topic.
     * 
     * @KafkaListener : Annotation magique de Spring Kafka.
     * 
     * Que fait @KafkaListener ?
     * 1. Au d√©marrage, Spring cr√©e un consumer Kafka en arri√®re-plan
     * 2. Le consumer s'abonne au topic sp√©cifi√©
     * 3. D√®s qu'un message arrive, cette m√©thode est appel√©e automatiquement
     * 4. Spring d√©s√©rialise le JSON en NotificationDTO (via JsonDeserializer)
     * 5. La m√©thode traite le message
     * 6. Si pas d'exception, Kafka commit l'offset (message marqu√© comme trait√©)
     * 
     * Param√®tres de l'annotation :
     * 
     * - topics : Liste des topics √† √©couter (peut √™tre plusieurs).
     *            ${...} : Lit depuis application.properties (kafka.topic.notifications)
     *            Avantage : Configuration externalis√©e, pas de hardcoding
     * 
     * - groupId : Identifiant du groupe de consommateurs.
     *             ${...} : Lit depuis application.properties (spring.kafka.consumer.group-id)
     *             
     *             R√¥le du group-id :
     *             - Tous les consumers avec le M√äME group-id forment un groupe
     *             - Kafka distribue les partitions entre les membres du groupe
     *             - Chaque message est trait√© par UN SEUL consumer du groupe
     *             - Permet la scalabilit√© horizontale (ajouter des consumers)
     *             
     *             Exemple avec 3 partitions et 2 consumers dans le m√™me groupe :
     *             - Consumer 1 traite partitions 0 et 1
     *             - Consumer 2 traite partition 2
     *             
     *             Si on a 2 applications avec des group-id DIFF√âRENTS :
     *             - Chaque groupe re√ßoit TOUS les messages (broadcast)
     * 
     * - containerFactory : (optionnel) Sp√©cifie une factory custom.
     *                      Si omis, Spring utilise la config par d√©faut.
     *                      Utile pour avoir plusieurs configs Kafka diff√©rentes.
     * 
     * Thread model :
     * - Par d√©faut, Spring cr√©e UN thread par partition assign√©e
     * - Les messages d'une partition sont trait√©s s√©quentiellement
     * - Les messages de partitions diff√©rentes sont trait√©s en parall√®le
     * - Pour notre d√©mo (1 partition) : traitement s√©quentiel simple
     * 
     * @param notification Le DTO d√©s√©rialis√© automatiquement depuis le JSON Kafka
     */
    @KafkaListener(
        topics = "${kafka.topic.notifications}",
        groupId = "${spring.kafka.consumer.group-id}"
    )
    public void listen(NotificationDto notification) {
        
        /**
         * √âTAPE 1 : Log de r√©ception pour tra√ßabilit√©.
         * 
         * info() : Niveau INFO car c'est une op√©ration normale importante.
         * 
         * Informations logg√©es :
         * - ID de la notification (pour corr√©lation avec les logs du producer)
         * - Titre (pour comprendre rapidement le type de notification)
         * - Type (INFO/SUCCESS/WARNING/ERROR)
         * 
         * Utilit√© en production :
         * - Monitoring : Compter combien de messages sont consomm√©s
         * - Debugging : V√©rifier qu'un message sp√©cifique est bien arriv√©
         * - Audit : Prouver la r√©ception d'une notification importante
         * 
         * Best practice : Logger AVANT le traitement (si traitement √©choue, 
         * on sait au moins que le message est arriv√©).
         */
        logger.info("üì© Received notification from Kafka - ID: {} | Title: {} | Type: {}",
                notification.id(),
                notification.title(),
                notification.type());

        /**
         * √âTAPE 2 : Validation optionnelle (bonnes pratiques).
         * 
         * M√™me si Kafka a bien d√©s√©rialis√©, on peut vouloir valider :
         * - Champs obligatoires non null
         * - Format de l'ID (UUID valide ?)
         * - Type dans la liste autoris√©e (INFO, SUCCESS, WARNING, ERROR)
         * - Longueur des champs (pas de message de 10 Mo)
         * 
         * Exemple de validation (√† d√©commenter si besoin) :
         */
        if (notification.title() == null || notification.title().isEmpty()) {
            logger.error("‚ùå Invalid notification received - Title is null or empty");
            // Option 1 : Return sans traiter (message sera commit quand m√™me)
            // Option 2 : Throw exception (message sera retry puis envoy√© en DLQ si configur√©)
            return;
        }
        
        // Validation du type (optionnel)
        String type = notification.type();
        if (type == null || !type.matches("INFO|SUCCESS|WARNING|ERROR")) {
            logger.warn("‚ö†Ô∏è  Unknown notification type: {} - Setting to INFO", type);
            notification =  NotificationDto.create(notification.id(), notification.title(), notification.message(), "INFO"); // Valeur par d√©faut
        }
        
        /**
         * √âTAPE 3 : Broadcast via WebSocket √† tous les clients connect√©s.
         * 
         * messagingTemplate.convertAndSend() : M√©thode cl√© de Spring WebSocket.
         * 
         * Param√®tres :
         * 1. destination : Chemin STOMP o√π envoyer ("/topic/notifications")
         * 2. payload : Objet Java √† envoyer (sera converti en JSON automatiquement)
         * 
         * Que se passe-t-il en interne ?
         * 1. Spring trouve tous les clients WebSocket abonn√©s √† "/topic/notifications"
         * 2. Convertit NotificationDTO en JSON (via Jackson MessageConverter)
         * 3. Envoie le JSON via WebSocket √† chaque client
         * 4. Retourne imm√©diatement (envoi asynchrone)
         * 
         * Diff√©rence avec convertAndSendToUser() :
         * - convertAndSend() : Broadcast √† TOUS les abonn√©s (public)
         * - convertAndSendToUser() : Envoie √† UN utilisateur sp√©cifique (priv√©)
         * 
         * Format du message STOMP envoy√© :
         * ```
         * MESSAGE
         * destination:/topic/notifications
         * content-type:application/json
         * 
         * {"id":"...","title":"...","message":"...","type":"...","timestamp":"..."}
         * ```
         * 
         * Clients Angular/JavaScript recevront ce JSON via leur subscription.
         */
        messagingTemplate.convertAndSend(notificationDestination, notification);
        
        /**
         * √âTAPE 4 : Log de succ√®s du broadcast.
         * 
         * Confirme que le message a √©t√© envoy√© aux WebSockets.
         * 
         * Important : Cela ne garantit PAS que les clients ont re√ßu !
         * - Si aucun client n'est connect√©, le message est perdu (c'est normal)
         * - Si un client est d√©connect√© au moment de l'envoi, il ne re√ßoit pas
         * - STOMP ne garantit pas la livraison (contrairement √† Kafka)
         * 
         * Pour garantir la livraison :
         * - Option 1 : Stocker les notifications en base (clients rattrapent au reconnect)
         * - Option 2 : Utiliser un vrai message broker (RabbitMQ, ActiveMQ)
         * - Option 3 : Impl√©menter un syst√®me de queue c√¥t√© client
         * 
         * Pour notre d√©mo : On accepte la perte potentielle (architecture simple).
         */
        logger.info("üì§ Notification broadcasted via WebSocket to {}", notificationDestination);
        
        /**
         * √âTAPE 5 : Traitement additionnel optionnel.
         * 
         * Exemples de traitements qu'on pourrait ajouter :
         * - Sauvegarder en base de donn√©es pour historique
         * - Envoyer un email pour les notifications ERROR
         * - Incr√©menter des m√©triques (Prometheus/Micrometer)
         * - Appeler un webhook externe
         * - D√©clencher d'autres √©v√©nements m√©tier
         * 
         * Exemple avec une base de donn√©es (√† impl√©menter si besoin) :
         */
        // notificationRepository.save(notification);
        // logger.debug("Notification saved to database");
        
        /**
         * √âTAPE 6 : Gestion des erreurs.
         * 
         * Que se passe-t-il si une exception est lanc√©e dans cette m√©thode ?
         * 
         * Comportement par d√©faut de Spring Kafka :
         * 1. L'exception est logg√©e par Spring
         * 2. Le message N'EST PAS commit (reste dans Kafka)
         * 3. Le consumer retry le m√™me message (boucle infinie possible !)
         * 
         * Solutions pour √©viter les boucles infinies :
         * 
         * A) Utiliser un ErrorHandler custom :
         * ```java
         * @Bean
         * public ConcurrentKafkaListenerContainerFactory<String, NotificationDTO> kafkaListenerContainerFactory() {
         *     factory.setCommonErrorHandler(new DefaultErrorHandler(
         *         new FixedBackOff(1000L, 3L) // 3 retries avec 1s entre chaque
         *     ));
         * }
         * ```
         * 
         * B) Wrapper la m√©thode dans un try-catch :
         */
        try {
            // Traitement risqu√© ici
        } catch (Exception e) {
            logger.error("‚ùå Error processing notification ID {}: {}", 
                        notification.id(), e.getMessage(), e);
            // Le message sera quand m√™me commit (on accepte la perte pour √©viter le blocage)
            // Alternative : Envoyer vers une Dead Letter Queue (DLQ)
        }
        
        /**
         * √âTAPE 7 : Commit de l'offset (automatique).
         * 
         * Si on arrive ici sans exception :
         * - Spring Kafka commit l'offset automatiquement (enable-auto-commit=true)
         * - Le message est marqu√© comme "trait√©" dans Kafka
         * - On ne le recevra plus jamais (sauf replay manuel)
         * 
         * Timing du commit :
         * - Par d√©faut : toutes les 1 seconde (auto-commit-interval=1000ms)
         * - Ou au prochain poll() si le batch est termin√©
         * 
         * Offset commit :
         * - Stock√© dans un topic interne Kafka : __consumer_offsets
         * - Format : (topic, partition, group-id) ‚Üí offset
         * - Permet au consumer de reprendre o√π il s'√©tait arr√™t√© apr√®s red√©marrage
         * 
         * Exemple :
         * - Message 1 trait√© ‚Üí offset=1 commit
         * - Message 2 trait√© ‚Üí offset=2 commit
         * - Crash du consumer
         * - Red√©marrage ‚Üí Reprend √† offset=3 (messages 1 et 2 d√©j√† trait√©s)
         */
    }
    
    /**
     * M√©thode utilitaire pour obtenir des statistiques (optionnel).
     * 
     * Peut √™tre expos√©e via un endpoint REST pour monitoring.
     * Exemple : GET /api/stats ‚Üí nombre de notifications trait√©es
     * 
     * Note : Pour compter, il faudrait ajouter un compteur :
     * private final AtomicLong processedCount = new AtomicLong(0);
     * Et l'incr√©menter dans listen() : processedCount.incrementAndGet();
     */
    // public long getProcessedCount() {
    //     return processedCount.get();
    // }
}